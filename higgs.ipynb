{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpigretti/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# llamadas al sistema\n",
    "import os\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "# write to file\n",
    "import csv\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_solution_dictionary(solution):\n",
    "    \"\"\" Read solution file, return a dictionary with key EventId and value (weight,label).\n",
    "    Solution file headers: EventId, Label, Weight \"\"\"\n",
    "    \n",
    "    solnDict = {}\n",
    "    with open(solution, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            if row[0] not in solnDict:\n",
    "                solnDict[row[0]] = (row[1], row[2])\n",
    "    return solnDict\n",
    "\n",
    "        \n",
    "def check_submission(submission, Nelements):\n",
    "    \"\"\" Check that submission RankOrder column is correct:\n",
    "        1. All numbers are in [1,NTestSet]\n",
    "        2. All numbers are unqiue\n",
    "    \"\"\"\n",
    "    rankOrderSet = set()    \n",
    "    with open(submission, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader) # header\n",
    "        for row in reader:\n",
    "            rankOrderSet.add(row[1])\n",
    "            \n",
    "    if len(rankOrderSet) != Nelements:\n",
    "        print('RankOrder column must contain unique values')\n",
    "        exit()\n",
    "    elif rankOrderSet.isdisjoint(set(range(1,Nelements+1))) == False:\n",
    "        print('RankOrder column must contain all numbers from [1..NTestSset]')\n",
    "        exit()\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "    \n",
    "def AMS(s, b):\n",
    "    \"\"\" Approximate Median Significance defined as:\n",
    "        AMS = sqrt(\n",
    "                2 { (s + b + b_r) log[1 + (s/(b+b_r))] - s}\n",
    "              )        \n",
    "    where b_r = 10, b = background, s = signal, log is natural logarithm \"\"\"\n",
    "    \n",
    "    br = 10.0\n",
    "    radicand = 2 *( (s+b+br) * math.log (1.0 + s/(b+br)) -s)\n",
    "    if radicand < 0:\n",
    "        print('radicand is negative. Exiting')\n",
    "        exit()\n",
    "    else:\n",
    "        return math.sqrt(radicand)\n",
    "\n",
    "\n",
    "def AMS_metric(solution, submission):\n",
    "    \"\"\"  Prints the AMS metric value to screen.\n",
    "    Solution File header: EventId, Class, Weight\n",
    "    Submission File header: EventId, RankOrder, Class\n",
    "    \"\"\"\n",
    "    # solutionDict: key=eventId, value=(label, class)\n",
    "    solutionDict = create_solution_dictionary(solution)\n",
    "\n",
    "    numEvents = len(solutionDict)\n",
    "    \n",
    "    signal = 0.0\n",
    "    background = 0.0\n",
    "    if check_submission(submission, numEvents):\n",
    "        with open(submission, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader) # header row\n",
    "            for row in reader:\n",
    "                if row[2] == 's': # only events predicted to be signal are scored\n",
    "                    if solutionDict[row[0]][0] == 's':\n",
    "                        signal += float(solutionDict[row[0]][1])\n",
    "                    elif solutionDict[row[0]][0] == 'b':\n",
    "                        background += float(solutionDict[row[0]][1])\n",
    "     \n",
    "        print('signal = {0}, background = {1}'.format(signal, background))\n",
    "        print('AMS = ' + str(AMS(signal, background)))\n",
    "    \n",
    "def WriteSolutionAndSubmission(solution_df, predicciones):\n",
    "    \"\"\"  \n",
    "        solution_df: data frame con EventId, Label y Weight. Los resultados correctos.\n",
    "        preddiciones: las predicciones.\n",
    "    \"\"\"\n",
    "    solution = pd.DataFrame()\n",
    "    solution[\"EventId\"] = solution_df[\"EventId\"]\n",
    "    solution[\"Class\"] = solution_df[\"Label\"]\n",
    "    solution[\"Weight\"] = solution_df[\"Weight\"]\n",
    "    f = open('./output/solution.csv',\"w+\")\n",
    "    solution.to_csv('./output/solution.csv', index = False)\n",
    "    solution.head()\n",
    "    #Armo Submission File Training:\n",
    "    submission = pd.DataFrame()\n",
    "    submission[\"EventId\"] = solution_df[\"EventId\"]\n",
    "    submission[\"RankOrder\"] = range(len(solution_df))\n",
    "    submission[\"Class\"] = predicciones\n",
    "    f = open('./output/submission.csv',\"w+\")\n",
    "    submission.to_csv('./output/submission.csv', index = False)\n",
    "\n",
    "def WriteSubmission(eventsId, rankOrders, predictions):\n",
    "    submission = pd.DataFrame()\n",
    "    submission[\"EventId\"] = eventsId\n",
    "    submission[\"RankOrder\"] = rankOrders\n",
    "    submission[\"Class\"] = predictions\n",
    "    f = open('./output/submission.csv',\"w+\")\n",
    "    submission.to_csv('./output/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chequear current working directory\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Leer input:\n",
    "train_df = pd.read_csv('./input/training.csv')\n",
    "test_df = pd.read_csv('./input/test.csv')\n",
    "random_subm = pd.read_csv('./input/random_submission.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explorar el training set:\n",
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# graficar pares\n",
    "#sns.pairplot(train, hue=\"Label\", vars=[\"PRI_jet_all_pt\", \"PRI_jet_subleading_phi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Posibles modelos:\n",
    "#GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_split=1e-07, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "dtc = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_split=1e-07, class_weight=None, presort=False)\n",
    "#dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features, sobre lo que se puede modelar:\n",
    "features = list(filter(lambda x: x != \"EventId\" and x != \"Weight\" and x != \"Label\", train_df.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76818399999999998"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un modelo:\n",
    "dtc = DecisionTreeClassifier(max_depth=2)\n",
    "# Lo entrenamos con el conjunto de training:\n",
    "dtc.fit(train_df[features], train_df[\"Label\"])\n",
    "# Vemos que resultado da con el conjunto de training:\n",
    "dtc.score(train_df[features], train_df[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predecimos:\n",
    "predicciones_train = dtc.predict(train_df[features])\n",
    "predicciones_test = dtc.predict(test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quiero testear la funciÃ³n de AMS. El conjunto de test es para la submission, no tiene los resultados.\n",
    "# Tengo que testearlo con lo de training.\n",
    "WriteSolutionAndSubmission(train_df, predicciones_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal = 467.706639594385, background = 55132.24700197646\n",
      "AMS = 1.9889281715125862\n"
     ]
    }
   ],
   "source": [
    "AMS_metric('./output/solution.csv', './output/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb = [xgb.XGBClassifier(max_depth=2, n_estimators=i, reg_lambda=0) for i in range(1,11)]\n",
    "\n",
    "\n",
    "for cla in gb: \n",
    "    cla.fit(train_df[features],  train_df[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal = 467.706639594385, background = 55132.24700197646\n",
      "AMS = 1.9889281715125862\n",
      "None\n",
      "signal = 438.0950675643611, background = 48172.195270770935\n",
      "AMS = 1.992823897685768\n",
      "None\n",
      "signal = 429.5431480429489, background = 33997.22033283691\n",
      "AMS = 2.324399614959424\n",
      "None\n",
      "signal = 434.5183979251309, background = 45371.12215331826\n",
      "AMS = 2.0364779083037714\n",
      "None\n",
      "signal = 447.4114688497362, background = 47475.311742328355\n",
      "AMS = 2.0499704600147686\n",
      "None\n",
      "signal = 423.7517742346038, background = 41935.954240446124\n",
      "AMS = 2.065559497305451\n",
      "None\n",
      "signal = 433.9196281729831, background = 43508.44134334942\n",
      "AMS = 2.076602132612116\n",
      "None\n",
      "signal = 439.6935353572142, background = 45610.02502876734\n",
      "AMS = 2.0553080212050747\n",
      "None\n",
      "signal = 409.8696953236512, background = 40953.662116096355\n",
      "AMS = 2.0217366709053137\n",
      "None\n",
      "signal = 435.49961035203825, background = 34820.89254455443\n",
      "AMS = 2.3286499079273093\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for cla in gb:\n",
    "    prediciones = cla.predict(train_df[features])\n",
    "    WriteSolutionAndSubmission(train_df, prediciones)\n",
    "    print(AMS_metric('./output/solution.csv', './output/submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = gb[2].predict(test_df[features])\n",
    "WriteSubmission(test_df[\"EventId\"], range(1,550001), predictions)\n",
    "check_submission('./output/submission.csv', 550000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[\"EventId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
